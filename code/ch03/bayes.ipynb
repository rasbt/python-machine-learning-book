{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayesian estimation\n",
    "\n",
    "A core concept in machine learning and related fields\n",
    "\n",
    "Probablistic views and concepts\n",
    "\n",
    "Bayes classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Conditional probability\n",
    "\n",
    "$p(A \\, | \\, B)$: the probability of event $A$ given $B$\n",
    "\n",
    "From basic probability:\n",
    "$$\n",
    "\\begin{align}\n",
    "p(A \\, | \\, B)\n",
    "&=\n",
    "\\frac{p(A \\bigcap B)}{p(B)}\n",
    "\\end{align}\n",
    "$$\n",
    "where $p(A \\bigcap B)$ is the joint probability, of $A$ and $B$ both happen.\n",
    "\n",
    "Alternative representation:\n",
    "$$\n",
    "\\begin{align}\n",
    "p(A \\bigcap B)\n",
    "&=\n",
    "p(A, B)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(A \\, | \\, B)\n",
    "&=\n",
    "\\frac{p(A, B)}{p(B)}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Assume $p(B) > 0$ as otherwise the question is ill-defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bayes' rule\n",
    "\n",
    "Apply conditional probability to the numerator again:\n",
    "$$\n",
    "\\begin{align}\n",
    "p(A \\, | \\, B)\n",
    "&=\n",
    "\\frac{p(A, B)}{p(B)}\n",
    "\\\\\n",
    "&=\n",
    "\\frac{p(B \\, | \\, A) p(A)}{p(B)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "To help remember, consider symmetry:\n",
    "$$\n",
    "\\begin{align}\n",
    "p(A, B)\n",
    "&=\n",
    "p(A \\, | \\, B) p(B)\n",
    "\\\\\n",
    "&=\n",
    "p(B \\, | \\, A) p(A)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## Classification\n",
    "\n",
    "$p(C \\, | \\, \\mathbf{x})$\n",
    "\n",
    "From an observed data $\\mathbf{x}$ we want to predict probability of $C$, the class label.\n",
    "\n",
    "We take a probabilistic view because real world is often non-deterministic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Iris example\n",
    "\n",
    "$C$: type of flower\n",
    "\n",
    "$\\mathbf{x}$: flower features\n",
    "\n",
    "<table style=\"width:100% border=0\">\n",
    "<tr>\n",
    "<td>\n",
    "<img src =\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Kosaciec_szczecinkowaty_Iris_setosa.jpg/220px-Kosaciec_szczecinkowaty_Iris_setosa.jpg\">\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Iris_versicolor_3.jpg/220px-Iris_versicolor_3.jpg\">\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Iris_virginica.jpg/220px-Iris_virginica.jpg\">\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr style=\"text-align=center\">\n",
    "<td>\n",
    "Setosa\n",
    "</td>\n",
    "<td>\n",
    "Versicolor\n",
    "</td>\n",
    "<td>\n",
    "Virginica\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Banking example\n",
    "\n",
    "A bank decides whether to make a loan to a customer:\n",
    "* $\n",
    "\\mathbf{x} = \n",
    "\\begin{pmatrix}\n",
    "x_1 \\\\\n",
    "x_2\n",
    "\\end{pmatrix}\n",
    "$\n",
    ": customer income $x_1$ and asset $x_2$\n",
    "\n",
    "* $C$: 0/1 if the customer is unlike/likely to pay back the loan\n",
    "\n",
    "Make a loan if $P(C = 1 \\, | \\, \\mathbf{x}) > 0.5$ or other threshold value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bayes' rule\n",
    "\n",
    "How to compute $P(C \\, | \\, \\mathbf{x})$, which is unknown?\n",
    "\n",
    "From conditional probability:\n",
    "$$\n",
    "\\begin{align}\n",
    "p\\left(C \\, | \\, \\mathbf{x}\\right)\n",
    "&= \n",
    "\\frac{p\\left(\\mathbf{x} \\, | \\, C\\right) p\\left(C\\right)}{p\\left(\\mathbf{x}\\right)}\n",
    "\\\\\n",
    "&\\propto\n",
    "p\\left(\\mathbf{x} \\, | \\, C\\right) p\\left(C\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "* $p(C \\, | \\, \\mathbf{x})$: posterior\n",
    "<br>\n",
    "the likelihood of $C$ given $\\mathbf{x}$\n",
    "\n",
    "* $p(C)$: prior\n",
    "<br>\n",
    "how likely $C$ is before observing $\\mathbf{x}$\n",
    "\n",
    "* $p(\\mathbf{x} \\, | \\, C)$: likelihood\n",
    "<br>\n",
    "how likely $\\mathbf{x}$ is if it belongs to $C$\n",
    "\n",
    "* $p(\\mathbf{x})$: marginal/evidence\n",
    "<br>\n",
    "constant for given $\\mathbf{x}$ \n",
    "\n",
    "We can compute $P(C \\, | \\, \\mathbf{x})$ (posterior), if given $p(C)$ (prior) and $p(\\mathbf{x} \\, | \\, C)$ (likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Rational decision making\n",
    "\n",
    "Humans tend to over focus on rare events\n",
    "\n",
    "For example:\n",
    "\n",
    "$\\mathbf{x}$: get killed\n",
    "\n",
    "$C$: cause of death\n",
    "* $C_{car}$: car crash\n",
    "* $C_{plane}$: airplane crash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Plane crash is much more deadly than car crash:\n",
    "$\n",
    "p(\\mathbf{x} \\, | \\, C_{plane}) \\gg p(\\mathbf{x} \\, | \\, C_{car})\n",
    "$\n",
    "\n",
    "say\n",
    "$\n",
    "\\begin{align}\n",
    "p(\\mathbf{x} \\, | \\, C_{plane}) &= 1.0\n",
    "\\\\\n",
    "p(\\mathbf{x} \\, | \\, C_{car}) &= 0.1\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "But plane crash is much rarer than car crash:\n",
    "$\n",
    "p(C_{plane}) \\ll p(C_{car})\n",
    "$\n",
    "\n",
    "say\n",
    "$\n",
    "\\begin{align}\n",
    "p(C_{plane}) &= 0.001 \\\\\n",
    "p(C_{car}) &= 0.1\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Multiply together:\n",
    "$\n",
    "\\begin{align}\n",
    "p(\\mathbf{x} \\, | \\, C_{plane}) p(C_{plane}) &= 0.001\n",
    "\\\\\n",
    "p(\\mathbf{x} \\, | \\, C_{car}) p(C_{car}) &= 0.01\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\n",
    "\\begin{align}\n",
    "\\frac{p(C_{plane} \\, | \\, \\mathbf{x})}{p(C_{car} \\, | \\, \\mathbf{x})}\n",
    "&=\n",
    "\\frac{p(\\mathbf{x} \\, | \\, C_{plane}) p(C_{plane})}{p(\\mathbf{x} \\, | \\, C_{car}) p(C_{car})}\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Thus plane travel is actually safter than car travel:\n",
    "$\n",
    "p(C_{plane} \\, | \\, \\mathbf{x}) < p(C_{car} \\, | \\, \\mathbf{x})\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Breast cancer example\n",
    "\n",
    "$C$: has cancer\n",
    "\n",
    "$\\overline{C}$: no cancer\n",
    "\n",
    "$1/0$: positive/negative cancer screening result\n",
    "\n",
    "$p(C) = 0.01$\n",
    "\n",
    "$C$:\n",
    "* $p(1 | C) = 0.8$\n",
    "* $p(0 | C) = 0.2$\n",
    "\n",
    "$\\overline{C}$:\n",
    "* $p(1 | \\overline{C}) = 0.1$\n",
    "* $p(0 | \\overline{C}) = 0.9$\n",
    "\n",
    "What is $p(C | 1)$?\n",
    "\n",
    "https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Other applications\n",
    "\n",
    "\n",
    "### Value \n",
    "\n",
    "$R(C_i\\, | \\mathbf{x})$: expected value (e.g. utility/loss/risk) for taking class $C_i$ given data $\\mathbf{x}$\n",
    "\n",
    "$R_{ik}$: value for taking class $C_i$ when the actual class is $C_k$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "R(C_i \\, | \\mathbf{x})\n",
    "=\n",
    "\\sum_{k} R_{ik} p(C_k \\, | \\, \\mathbf{x})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Goal: select $C_i$ to optimize $R(C_i \\, | \\, \\mathbf{x})$ given $\\mathbf{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "### Association\n",
    "\n",
    "$\n",
    "X \\rightarrow Y\n",
    "$\n",
    "* $X$: antecedent\n",
    "* $Y$: consequent\n",
    "\n",
    "Example: basket analysis for shopping,\n",
    "$X$ and $Y$ can be sets of item(s).\n",
    "\n",
    "Support:\n",
    "$$\n",
    "p(X, Y)\n",
    "$$\n",
    ", the statistical significance of having $X$ and $Y$ together\n",
    "\n",
    "Confidence:\n",
    "$$\n",
    "p(Y | X)\n",
    "$$\n",
    ", how likely $Y$ can be predicted from $X$\n",
    "\n",
    "Lift:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{p(X, Y)}{p(X)p(Y)}\n",
    "&=\n",
    "\\frac{p(Y | X)}{p(Y)}\n",
    "\\end{align}\n",
    "$$\n",
    ", $> 1$, $< 1$, $=1$, $X$ makes $Y$ more, less, equally likely "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Learning\n",
    "\n",
    "From training data $\\mathbf{X}$ we want to estimate model parameters $\\Theta$.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p\\left(\\Theta | \\mathbf{X}\\right)\n",
    "&= \n",
    "\\frac{p\\left(\\mathbf{X} | \\Theta\\right) p\\left(\\Theta\\right)}{p\\left(\\mathbf{X}\\right)}\n",
    "\\\\\n",
    "&\\propto\n",
    "p\\left(\\mathbf{X} | \\Theta\\right) p\\left(\\Theta\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "* $p(\\Theta | \\mathbf{X})$: posterior\n",
    "<br>\n",
    "the likelihood of $\\Theta$ given $\\mathbf{X}$\n",
    "\n",
    "* $p(\\Theta)$: prior\n",
    "<br>\n",
    "how likely $\\Theta$ is before observing $\\mathbf{X}$\n",
    "\n",
    "* $p(\\mathbf{X} | \\Theta)$: likelihood\n",
    "<br>\n",
    "how likely $\\mathbf{X}$ is if the model parameters are $\\Theta$\n",
    "\n",
    "* $p(\\mathbf{X})$: marginal/evidence\n",
    "<br>\n",
    "constant for given $\\mathbf{X}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### MAP (maximum a posteriori) estimation\n",
    "$$\n",
    "\\Theta_{MAP} = argmax_{\\Theta} p(\\Theta | \\mathbf{X})\n",
    "$$\n",
    "\n",
    "If we don't have $p(\\Theta)$, it can be assumed to be flat\n",
    "$\n",
    "p(\\Theta) = 1\n",
    "$\n",
    "and MAP is equivalent to ML:\n",
    "\n",
    "### ML (maximum likelihood) estimation\n",
    "$$\n",
    "\\Theta_{ML} = argmax_{\\Theta} p(\\mathbf{X} | \\Theta)\n",
    "$$\n",
    "\n",
    "Under the often iid (identical and independently distributed) assumption:\n",
    "$$\n",
    "p(\\mathbf{X} | \\Theta) = \\prod_{t=1}^{N} p(\\mathbf{x}^{(t)} | \\Theta)\n",
    "$$\n",
    ", where $\\{\\mathbf{x}^{t}\\}$ are the individual samples within $\\mathbf{X}$.\n",
    "($\\mathbf{X}$ is a matrix and $\\{\\mathbf{x}^{t}\\}$ are its individual columns.)\n",
    "\n",
    "### Bayes estimator\n",
    "The expected value of the posterior density:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Theta_{Bayes} \n",
    "&=\n",
    "E(\\Theta | \\mathbf{X}) \n",
    "\\\\\n",
    "&= \n",
    "\\int \\Theta p(\\Theta | \\mathbf{X}) d\\Theta\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The best estimate of a random variable/vector is its mean.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Gaussian example\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(\\mathbf{X} | \\Theta)\n",
    "&=\n",
    "\\frac{1}{(2\\pi)^{N/2}\\sigma^N} \\exp\\left(-\\frac{\\sum_{t=1}^N (\\mathbf{x}^{(t)} - \\Theta)^2}{2\\sigma^2}\\right)\n",
    "\\\\\n",
    "p(\\Theta)\n",
    "&=\n",
    "\\frac{1}{\\sqrt{2\\pi}\\sigma_0} \\exp\\left( -\\frac{(\\Theta - \\mu_0)^2}{2\\sigma_0^2} \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "### ML (maximum likelihood) estimation \n",
    "$$\n",
    "\\Theta_{ML} = argmax_{\\Theta} p(\\mathbf{X} | \\Theta)\n",
    "$$\n",
    "\n",
    "Compute the data $\\mathbf{X}$ mean and variance:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Theta_{ML} &= \\mathbf{m} = \\frac{\\sum_{t=1}^N \\mathbf{x}^{(t)}}{N}\n",
    "\\\\\n",
    "\\sigma_{ML}^2 &= s^2 = \\frac{\\sum_{t=1}^N \\left(\\mathbf{x} - \\mathbf{m} \\right)^2}{N}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The $\\mathbf{m}$ part holds regardless of $\\sigma$ (constant or a variable to be optimized).\n",
    "\n",
    "### MAP estimation\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Theta_{MAP} \n",
    "&= \n",
    "argmax_{\\Theta} p(\\Theta | \\mathbf{X})\n",
    "\\\\\n",
    "&=\n",
    "argmax_{\\Theta} p(\\mathbf{X} | \\Theta) p(\\Theta)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "It can be shown that\n",
    "$$\n",
    "\\Theta_{MAP} =\n",
    "\\frac{N/\\sigma^2}{N/\\sigma^2 + 1/\\sigma_0^2} \\mathbf{m}\n",
    "+\n",
    "\\frac{1/\\sigma_0^2}{N/\\sigma^2 + 1/\\sigma_0^2} \\mu_0\n",
    "$$\n",
    ", i.e. weighted average of prior mean $\\mu_0$ and sample $\\mathbf{X}$ mean $\\mathbf{m}$, with weights inversely proportional to variances.\n",
    "\n",
    "Note that if we don't know $p(\\Theta)$, we can assume it is a constant distribution $p(\\Theta) = 1$, i.e. $\\sigma_0 = \\infty$.\n",
    "This will give us $\\Theta_{MAP} = \\mathbf{m} = \\Theta_{ML}$, as expected.\n",
    "\n",
    "### Bayes estimation\n",
    "\n",
    "$$\n",
    "\\Theta_{Bayes} = E(\\Theta | \\mathbf{X}) =\n",
    "\\frac{N/\\sigma^2}{N/\\sigma^2 + 1/\\sigma_0^2} \\mathbf{m}\n",
    "+\n",
    "\\frac{1/\\sigma_0^2}{N/\\sigma^2 + 1/\\sigma_0^2} \\mu_0\n",
    "$$\n",
    ", i.e. same as $\\Theta_{MAP}$.\n",
    "\n",
    "The math derivations are left as exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Naive Bayes\n",
    "\n",
    "Naive Bayes assume the features are independent for the likelihood, i.e. for an $n$-dimensional data vector $\\mathbf{x}$\n",
    "$$\n",
    "\\begin{align}\n",
    "p(\\mathbf{x} | \\Theta) \n",
    "&=\n",
    "p(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots \\mathbf{x}_n | \\Theta)\n",
    "\\\\\n",
    "&=\n",
    "\\prod_{k=1}^n p( \\mathbf{x}_k | \\Theta)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We can generalize from a single data item $\\mathbf{x}$ (a vector) to an entire data set $\\mathbf{X}$ (a matrix whose columns are data items) by considering columns of $\\mathbf{X}$ as features, i.e. $\\mathbf{X}_{(k)}$\n",
    "\n",
    "Put the above into our Bayesian rule:\n",
    "$$\n",
    "\\begin{align}\n",
    "p(\\Theta | \\mathbf{X})\n",
    "&=\n",
    "\\frac{p(\\Theta) p\\left(\\mathbf{X} | \\Theta\\right)}{p(\\mathbf{X})}\n",
    "\\\\\n",
    "&=\n",
    "\\frac{p(\\Theta) \\prod_{k=1}^n p\\left(\\mathbf{X}_{(k)} | \\Theta\\right)}{p(\\mathbf{X})}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The main merit of naive Bayes is that the estimation/computation of individual \n",
    "$\n",
    "p\\left(\\mathbf{X}_{(k)} | \\Theta\\right)\n",
    "$\n",
    "terms is easier/faster than the joint term\n",
    "$\n",
    "p\\left(\\mathbf{X} | \\Theta \\right)\n",
    "$\n",
    ".\n",
    "\n",
    "This feature independence is just an assumption, but tends to work well in practice.\n",
    "\n",
    "More details can be found under:\n",
    "* http://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "* https://en.wikipedia.org/wiki/Naive_Bayes_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Code example\n",
    "\n",
    "scikit learn supports naive Bayes with different math functions for the likelihood, such as Gaussian, Bernoulli, and multinomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data[:, [2, 3]]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# splitting data into 70% training and 30% test data: \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "_ = gnb.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "y_pred = gnb.predict(X_test_std)\n",
    "\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
